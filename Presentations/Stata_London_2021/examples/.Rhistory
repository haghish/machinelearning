# -------------------------------------------------
costModelBoosted <- C5.0(train[-17], train$default, trials = 10, costs = error_cost)
predictCostBoost <- predict(costModelBoosted, test)
CrossTable(test$default, predictCostBoost,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
# Adding cost matrix
# =========================================================================
matrix_dimensions <- list(c("1", "2"), c("1", "2"))
names(matrix_dimensions) <- c("predicted", "actual")
matrix_dimensions
# Suppose we believe that a loan default costs the bank four times as much as a missed opportunity
error_cost <- matrix(c(0, 1, 6, 0), nrow = 2,
dimnames = matrix_dimensions)
#  there is no cost assigned when the algorithm classifies a no or yes correctly,
#  but a false negative has a cost of 4 versus a false positive's cost of 1.
costModel <- C5.0(train[-17], train$default, costs = error_cost)
#summary(costModel)
predictCost <- predict(costModel, test)
CrossTable(test$default, predictCost,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
CrossTable(test$default, predictCostBoost,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
# Expanding with boosting and penalty (cost matrix)
# -------------------------------------------------
error_cost <- matrix(c(0, 1, 10, 0), nrow = 2,
dimnames = matrix_dimensions)
costModelBoosted <- C5.0(train[-17], train$default, trials = 10, costs = error_cost)
predictCostBoost <- predict(costModelBoosted, test)
CrossTable(test$default, predictCostBoost,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
error_cost <- matrix(c(0, 1, 20, 0), nrow = 2,
dimnames = matrix_dimensions)
costModelBoosted <- C5.0(train[-17], train$default, trials = 10, costs = error_cost)
predictCostBoost <- predict(costModelBoosted, test)
CrossTable(test$default, predictCostBoost,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
error_cost <- matrix(c(0, 1, 8, 0), nrow = 2,
dimnames = matrix_dimensions)
costModelBoosted <- C5.0(train[-17], train$default, trials = 10, costs = error_cost)
predictCostBoost <- predict(costModelBoosted, test)
CrossTable(test$default, predictCostBoost,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
error_cost <- matrix(c(0, 1, 4, 0), nrow = 2,
dimnames = matrix_dimensions)
costModelBoosted <- C5.0(train[-17], train$default, trials = 10, costs = error_cost)
predictCostBoost <- predict(costModelBoosted, test)
CrossTable(test$default, predictCostBoost,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
# Expanding with boosting and penalty (cost matrix)
# -------------------------------------------------
error_cost <- matrix(c(0, 1, 8, 0), nrow = 2,
dimnames = matrix_dimensions)
costModelBoosted <- C5.0(train[-17], train$default, trials = 10, costs = error_cost)
predictCostBoost <- predict(costModelBoosted, test)
CrossTable(test$default, predictCostBoost,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
error_cost <- matrix(c(0, 1, 8, 0), nrow = 2,
dimnames = matrix_dimensions)
costModelBoosted <- C5.0(train[-17], train$default, trials = 40, costs = error_cost)
predictCostBoost <- predict(costModelBoosted, test)
CrossTable(test$default, predictCostBoost,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
error_cost <- matrix(c(0, 1, 8, 0), nrow = 2,
dimnames = matrix_dimensions)
costModelBoosted <- C5.0(train[-17], train$default, trials = 8, costs = error_cost)
predictCostBoost <- predict(costModelBoosted, test)
CrossTable(test$default, predictCostBoost,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
error_cost <- matrix(c(0, 1, 8, 0), nrow = 2,
dimnames = matrix_dimensions)
costModelBoosted <- C5.0(train[-17], train$default, trials = 10, costs = error_cost)
predictCostBoost <- predict(costModelBoosted, test)
CrossTable(test$default, predictCostBoost,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
error_cost <- matrix(c(0, 1, 2, 0), nrow = 2,
dimnames = matrix_dimensions)
costModelBoosted <- C5.0(train[-17], train$default, trials = 10, costs = error_cost)
predictCostBoost <- predict(costModelBoosted, test)
CrossTable(test$default, predictCostBoost,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
error_cost <- matrix(c(0, 1, 100, 0), nrow = 2,
dimnames = matrix_dimensions)
costModelBoosted <- C5.0(train[-17], train$default, trials = 10, costs = error_cost)
predictCostBoost <- predict(costModelBoosted, test)
CrossTable(test$default, predictCostBoost,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
error_cost <- matrix(c(0, 1, 8, 0), nrow = 2,
dimnames = matrix_dimensions)
costModelBoosted <- C5.0(train[-17], train$default, trials = 10, costs = error_cost)
predictCostBoost <- predict(costModelBoosted, test)
CrossTable(test$default, predictCostBoost,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
CrossTable(test$default, predictCost,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
# Suppose we believe that a loan default costs the bank four times as much as a missed opportunity
error_cost <- matrix(c(0, 1, 4, 0), nrow = 2,
dimnames = matrix_dimensions)
#  there is no cost assigned when the algorithm classifies a no or yes correctly,
#  but a false negative has a cost of 4 versus a false positive's cost of 1.
costModel <- C5.0(train[-17], train$default, costs = error_cost)
#summary(costModel)
predictCost <- predict(costModel, test)
CrossTable(test$default, predictCost,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
error_cost <- matrix(c(0, 1, 2, 0), nrow = 2,
dimnames = matrix_dimensions)
#  there is no cost assigned when the algorithm classifies a no or yes correctly,
#  but a false negative has a cost of 4 versus a false positive's cost of 1.
costModel <- C5.0(train[-17], train$default, costs = error_cost)
#summary(costModel)
predictCost <- predict(costModel, test)
CrossTable(test$default, predictCost,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
error_cost <- matrix(c(0, 1, 4, 0), nrow = 2,
dimnames = matrix_dimensions)
costModelBoosted <- C5.0(train[-17], train$default, trials = 10, costs = error_cost)
predictCostBoost <- predict(costModelBoosted, test)
CrossTable(test$default, predictCostBoost,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
error_cost <- matrix(c(0, 1, 2, 0), nrow = 2,
dimnames = matrix_dimensions)
costModelBoosted <- C5.0(train[-17], train$default, trials = 10, costs = error_cost)
predictCostBoost <- predict(costModelBoosted, test)
CrossTable(test$default, predictCostBoost,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
error_cost <- matrix(c(0, 1, 4, 0), nrow = 2,
dimnames = matrix_dimensions)
costModelBoosted <- C5.0(train[-17], train$default, trials = 5, costs = error_cost)
predictCostBoost <- predict(costModelBoosted, test)
CrossTable(test$default, predictCostBoost,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
error_cost <- matrix(c(0, 1, 4, 0), nrow = 2,
dimnames = matrix_dimensions)
costModelBoosted <- C5.0(train[-17], train$default, trials = 3, costs = error_cost)
predictCostBoost <- predict(costModelBoosted, test)
CrossTable(test$default, predictCostBoost,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
error_cost <- matrix(c(0, 1, 4, 0), nrow = 2,
dimnames = matrix_dimensions)
costModelBoosted <- C5.0(train[-17], train$default, trials = 10, costs = error_cost)
predictCostBoost <- predict(costModelBoosted, test)
CrossTable(test$default, predictCostBoost,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
# Expanding with boosting and penalty (cost matrix)
# -------------------------------------------------
error_cost <- matrix(c(0, 1, 1, 0), nrow = 2,
dimnames = matrix_dimensions)
costModelBoosted <- C5.0(train[-17], train$default, trials = 10, costs = error_cost)
predictCostBoost <- predict(costModelBoosted, test)
CrossTable(test$default, predictCostBoost,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
# Using CARET for optimizing the model
# ====================================
library(caret)
error_cost <- matrix(c(0, 1, 2, 0), nrow = 2,
dimnames = matrix_dimensions)
costModelBoosted <- C5.0(train[-17], train$default, trials = 10, costs = error_cost)
predictCostBoost <- predict(costModelBoosted, test)
CrossTable(test$default, predictCostBoost,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
# -------------------------------------------------
error_cost <- matrix(c(0, 1, 4, 0), nrow = 2,
dimnames = matrix_dimensions)
costModelBoosted <- C5.0(train[-17], train$default, trials = 10, costs = error_cost)
predictCostBoost <- predict(costModelBoosted, test)
CrossTable(test$default, predictCostBoost,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
# -------------------------------------------------
error_cost <- matrix(c(0, 1, 4, 0), nrow = 2,
dimnames = matrix_dimensions)
costModelBoosted <- C5.0(train[-17], train$default, trials = 10, costs = error_cost)
predictCostBoost <- predict(costModelBoosted, test)
CrossTable(test$default, predictCostBoost,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
matrix_dimensions <- list(c("1", "2"), c("1", "2"))
names(matrix_dimensions) <- c("predicted", "actual")
matrix_dimensions
# Suppose we believe that a loan default costs the bank four times as much as a missed opportunity
error_cost <- matrix(c(0, 1, 4, 0), nrow = 2,
dimnames = matrix_dimensions)
#  there is no cost assigned when the algorithm classifies a no or yes correctly,
#  but a false negative has a cost of 4 versus a false positive's cost of 1.
costModel <- C5.0(train[-17], train$default, costs = error_cost)
#summary(costModel)
predictCost <- predict(costModel, test)
CrossTable(test$default, predictCost,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
matrix_dimensions <- list(c("1", "2"), c("1", "2"))
names(matrix_dimensions) <- c("predicted", "actual")
matrix_dimensions
# Suppose we believe that a loan default costs the bank four times as much as a missed opportunity
error_cost <- matrix(c(0, 1, 8, 0), nrow = 2,
dimnames = matrix_dimensions)
#  there is no cost assigned when the algorithm classifies a no or yes correctly,
#  but a false negative has a cost of 4 versus a false positive's cost of 1.
costModel <- C5.0(train[-17], train$default, costs = error_cost)
#summary(costModel)
predictCost <- predict(costModel, test)
CrossTable(test$default, predictCost,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
error_cost <- matrix(c(0, 1, 20, 0), nrow = 2,
dimnames = matrix_dimensions)
#  there is no cost assigned when the algorithm classifies a no or yes correctly,
#  but a false negative has a cost of 4 versus a false positive's cost of 1.
costModel <- C5.0(train[-17], train$default, costs = error_cost)
#summary(costModel)
predictCost <- predict(costModel, test)
CrossTable(test$default, predictCost,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
error_cost <- matrix(c(0, 1, 10, 0), nrow = 2,
dimnames = matrix_dimensions)
#  there is no cost assigned when the algorithm classifies a no or yes correctly,
#  but a false negative has a cost of 4 versus a false positive's cost of 1.
costModel <- C5.0(train[-17], train$default, costs = error_cost)
#summary(costModel)
predictCost <- predict(costModel, test)
CrossTable(test$default, predictCost,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
error_cost <- matrix(c(0, 1, 8, 0), nrow = 2,
dimnames = matrix_dimensions)
#  there is no cost assigned when the algorithm classifies a no or yes correctly,
#  but a false negative has a cost of 4 versus a false positive's cost of 1.
costModel <- C5.0(train[-17], train$default, costs = error_cost)
#summary(costModel)
predictCost <- predict(costModel, test)
CrossTable(test$default, predictCost,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
error_cost <- matrix(c(0, 1, 6, 0), nrow = 2,
dimnames = matrix_dimensions)
#  there is no cost assigned when the algorithm classifies a no or yes correctly,
#  but a false negative has a cost of 4 versus a false positive's cost of 1.
costModel <- C5.0(train[-17], train$default, costs = error_cost)
#summary(costModel)
predictCost <- predict(costModel, test)
CrossTable(test$default, predictCost,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
set.seed(300)
m <- train(default ~ ., data = credit, method = "C5.0")
m
summary(m)
m
n <- train(default ~ ., data = credit, method = "C5.0", costs = error_cost)
n
error_cost <- matrix(c(0, 1, 4, 0), nrow = 2,
dimnames = matrix_dimensions)
n <- train(default ~ ., data = credit, method = "C5.0", costs = error_cost)
n
p <- predict(m, credit)
p
table(p, credit$default)
p <- predict(m, test)
table(p, credit$default)
table(p, test$default)
p <- predict(n, test)
table(p, test$default)
?train
?C50
?C5Â´
?C5
?C5.0
CrossTable(test$default, p,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
p <- predict(n, test)
CrossTable(test$default, p,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
p <- predict(m, test)
CrossTable(test$default, p,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
m <- train(default ~ ., data = train, method = "C5.0")
p <- predict(m, test)
CrossTable(test$default, p,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
error_cost <- matrix(c(0, 1, 4, 0), nrow = 2,
dimnames = matrix_dimensions)
n <- train(default ~ ., data = train, method = "C5.0", costs = error_cost)
p <- predict(n, test)
CrossTable(test$default, p,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
error_cost <- matrix(c(0, 1, 2, 0), nrow = 2,
dimnames = matrix_dimensions)
n <- train(default ~ ., data = train, method = "C5.0", costs = error_cost)
p2 <- predict(n, test)
CrossTable(test$default, p2,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
# create the grid
grid <- expand.grid(.model = "tree",
.trials = c(1, 5, 10, 15, 20, 25, 30, 35),
.winnow = "FALSE")
set.seed(300)
m <- train(default ~ ., data = credit, method = "C5.0",
metric = "Kappa",
trControl = ctrl,
tuneGrid = grid)
m <- train(default ~ ., data = train, method = "C5.0",
metric = "Kappa",
trControl = ctrl,
tuneGrid = grid)
# create an object for trainControl()
ctrl <- trainControl(method = "cv", number = 10,
selectionFunction = "oneSE")
# create the grid
grid <- expand.grid(.model = "tree",
.trials = c(1, 5, 10, 15, 20, 25, 30, 35),
.winnow = "FALSE")
set.seed(300)
m <- train(default ~ ., data = train, method = "C5.0",
metric = "Kappa",
trControl = ctrl,
tuneGrid = grid)
o <- train(default ~ ., data = train, method = "C5.0",
metric = "Kappa",
trControl = ctrl,
tuneGrid = grid)
m <- train(default ~ ., data = train, method = "C5.0")
p <- predict(o, test)
CrossTable(test$default, p,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
o
# Chapter 11: Bagging
# ------------------------------------------------------------------------------
library(ipred)
set.seed(300)
mybag <- bagging(default ~ ., data = credit, nbagg = 25)
bagPred <- predict(mybag, credit)
table(bagPred, credit$default)
mybag <- bagging(default ~ ., data = train, nbagg = 25)
mybag <- bagging(default ~ ., data = train, nbagg = 50)
bagPred <- predict(mybag, test)
CrossTable(test$default, bagPred,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
set.seed(300)
mybag <- bagging(default ~ ., data = train, nbagg = 25)
bagPred <- predict(mybag, test)
CrossTable(test$default, bagPred,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
set.seed(300)
mybag <- bagging(default ~ ., data = train, nbagg = 100)
bagPred <- predict(mybag, test)
CrossTable(test$default, bagPred,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
set.seed(300)
mybag <- bagging(default ~ ., data = train, nbagg = 1000)
bagPred <- predict(mybag, test)
CrossTable(test$default, bagPred,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
set.seed(300)
mybag <- bagging(default ~ ., data = train, nbagg = 10000)
bagPred <- predict(mybag, test)
CrossTable(test$default, bagPred,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
# using caret package for bagging
library(caret)
set.seed(300)
ctrl <- trainControl(method = "cv", number = 10)
train(default ~ ., data = credit, method = "treebag",
trControl = ctrl)
# bagged support vector machine model
# ...................................
bagctrl <- bagControl(fit = svmBag$fit,
predict = svmBag$pred,
aggregate = svmBag$aggregate)
svmBag
svmBag()
?svmBag
# bagged support vector machine model
# ...................................
str(svmBag)
svmBag$fit
bagctrl <- bagControl(fit = svmBag$fit,
predict = svmBag$pred,
aggregate = svmBag$aggregate)
library(kernlab)
set.seed(300)
svmbag <- train(default ~ ., data = credit, "bag",
trControl = ctrl, bagControl = bagctrl)
svmbag
ctrl <- trainControl(method = "cv", number = 10)
bagctrl <- bagControl(fit = svmBag$fit,
predict = svmBag$pred,
aggregate = svmBag$aggregate)
set.seed(300)
svmbag <- train(default ~ ., data = credit, "bag",
trControl = ctrl, bagControl = bagctrl)
warnings()
# Chapter 11: Boosting
# ------------------------------------------------------------------------------
library(adabag)
install.packages("adabag")
# Chapter 11: Boosting
# ------------------------------------------------------------------------------
library(adabag)
set.seed(300)
m_adaboost <- boosting(default ~ ., data = credit)
p_adaboost <- predict(m_adaboost, credit)
head(p_adaboost$class)
p_adaboost$confusion
# For a more accurate assessment of performance on unseen data, we need to use another evaluation method
set.seed(300)
adaboost_cv <- boosting.cv(default ~ ., data = credit)
adaboost_cv$confusion
#We can find the kappa statistic using the vcd package as described in Chapter 10
library(vcd)
install.packages("vcd")
Kappa(adaboost_cv$confusion)
#We can find the kappa statistic using the vcd package as described in Chapter 10
library(vcd)
Kappa(adaboost_cv$confusion)
# this performed extraordinary! let's try it on training data
adaboost_cv <- boosting.cv(default ~ ., data = train)
adaboost_cv$confusion
p_adaboost <- predict(adaboost_cv, test)
p_adaboost$confusion
adaboost_cv$class
View(adaboost_cv)
View(credit)
nona <- na.omit(credit)
adaboost_cv <- boosting.cv(default ~ ., data = nona)
m_adaboost <- boosting(default ~ ., data = nona)
p_adaboost <- predict(m_adaboost, nona)
head(p_adaboost$class)
p_adaboost$confusion
m_adaboost <- boosting(default ~ ., data = credit)
p_adaboost <- predict(m_adaboost, credit)
p_adaboost$confusion
# Chapter 11: Random Forest
# ------------------------------------------------------------------------------
library(randomForest)
set.seed(300)
rf <- randomForest(default ~ ., data = credit)
rf
m_adaboost <- boosting(default ~ ., data = train)
View(credit)
p_adaboost <- predict(m_adaboost, test)
p_adaboost$confusion
?boosting
# a real test...
m_adaboost <- boosting(default ~ ., data = train, boost=FALSE)
p_adaboost <- predict(m_adaboost, test)
p_adaboost$confusion
m_adaboost <- boosting(default ~ ., data = train, boost=TRUE, mfinal=1000)
p_adaboost <- predict(m_adaboost, test)
p_adaboost$confusion
m_adaboost <- boosting(default ~ ., data = train, boost=FALSE, mfinal=1000)
p_adaboost <- predict(m_adaboost, test)
p_adaboost$confusion
# Chapter 11: comparing random forest with C50
# ------------------------------------------------------------------------------
library(caret)
ctrl <- trainControl(method = "repeatedcv",
number = 10, repeats = 10)
grid_c50 <- expand.grid(.model = "tree",
.trials = c(10, 20, 30, 40),
.winnow = "FALSE")
grid_rf <- expand.grid(.mtry = c(2, 4, 8, 16))
set.seed(300)
m_rf <- train(default ~ ., data = credit, method = "rf",
metric = "Kappa", trControl = ctrl,
tuneGrid = grid_rf)
19/25
19/26
set.seed(300)
grid_c50 <- expand.grid(.model = "tree",
.trials = c(10, 20, 30, 40),
.winnow = "FALSE")
set.seed(300)
m_c50 <- train(default ~ ., data = credit, method = "C5.0",
metric = "Kappa", trControl = ctrl,
tuneGrid = grid_c50)
